{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomedical Image Segmentation with U-Net\n",
    "\n",
    "In this code example, we apply the U-Net architecture to segment brain tumors from raw MRI scans as shown below. With relatively little data we are able to train a U-Net model to accurately predict where tumors exist. \n",
    "\n",
    "The Dice coefficient (the standard metric for the BraTS dataset used in the study) for our model is about 0.82-0.88.  Menze et al. [reported](http://ieeexplore.ieee.org/document/6975210/) that expert neuroradiologists manually segmented these tumors with a cross-rater Dice score of 0.75-0.85, meaning that the model’s predictions are on par with what expert physicians have made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/figure1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since its introduction two years ago, the [U-Net](https://arxiv.org/pdf/1505.04597.pdf0) architecture has been used to create deep learning models for segmenting [nerves](https://github.com/jocicmarko/ultrasound-nerve-segmentation) in ultrasound images, [lungs](https://www.kaggle.com/c/data-science-bowl-2017#tutorial) in CT scans, and even [interference](https://github.com/jakeret/tf_unet) in radio telescopes.\n",
    "\n",
    "## What is U-Net?\n",
    "U-Net is designed like an [auto-encoder](https://en.wikipedia.org/wiki/Autoencoder). It has an encoding path (“contracting”) paired with a decoding path (“expanding”) which gives it the “U” shape.  However, in contrast to the autoencoder, U-Net predicts a pixelwise segmentation map of the input image rather than classifying the input image as a whole. For each pixel in the original image, it asks the question: “To which class does this pixel belong?” This flexibility allows U-Net to predict different parts of the tumor simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/unet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module loads the data from data.py, creates a TensorFlow/Keras model from model.py, trains the model on the data, and then saves the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data format = channels_last\n",
      "We are using Tensorflow version\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import time\n",
    "import os\n",
    "import settings    # Use the custom settings.py file for default parameters\n",
    "import onnxmltools\n",
    "\n",
    "import sys; sys.argv=['']; del sys\n",
    "from model import load_model, get_callbacks, evaluate_model\n",
    "from data import load_data\n",
    "\n",
    "from argparser import args\n",
    "\n",
    "if args.keras_api:\n",
    "    import keras as K\n",
    "else:\n",
    "    from tensorflow import keras as K\n",
    "\n",
    "print (\"We are using Tensorflow version\", tf.__version__,\\\n",
    "       \"with Intel(R) MKL\", \"enabled\" if tf.pywrap_tensorflow.IsMklEnabled() else \"disabled\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For best CPU speed set the number of intra and inter threads to take advantage of multi-core systems.\n",
    "See https://github.com/intel/mkl-dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Set the multi-threading parameters for Tensorflow. \n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=args.num_threads,\n",
    "                        inter_op_parallelism_threads=args.num_inter_threads)\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "K.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(data_path, data_filename, batch_size, n_epoch, onnx=False):\n",
    "    \"\"\"\n",
    "    Create a model, load the data, and train it.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Step 1: Load the data\n",
    "    \"\"\"\n",
    "    hdf5_filename = os.path.join(data_path, data_filename)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Loading the data from HDF5 file ...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    imgs_train, msks_train, imgs_validation, msks_validation = load_data(hdf5_filename)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Creating and compiling model ...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    \"\"\"\n",
    "    Step 2: Define the model\n",
    "    \"\"\"\n",
    "    model = load_model(imgs_train.shape, msks_train.shape)\n",
    "\n",
    "    model_filename, model_callbacks = get_callbacks()\n",
    "\n",
    "    \"\"\"\n",
    "    Step 3: Train the model on the data\n",
    "    \"\"\"\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Fitting model with training data ...\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    if onnx:\n",
    "        for i in range(0,30):\n",
    "            print (\"Processing batch:\", i)\n",
    "            start_time = time.time()\n",
    "            model.train_on_batch(imgs_train[i*batch_size:batch_size*(i+1)-1], \\\n",
    "                                 msks_train[i*batch_size:batch_size*(i+1)-1])\n",
    "            print (\"Time for training on batch:\", time.time() - start_time) \n",
    "\n",
    "        # TODO: Convert the Keras model to ONNX and save it. \n",
    "        onnx_model = onnxmltools.convert_keras(model, target_opset=7) \n",
    "        onnxmltools.utils.save_model(onnx_model, 'output/unet_model_for_decathlon.onnx')\n",
    "    else:\n",
    "        history = model.fit(imgs_train, msks_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=n_epoch,\n",
    "                            validation_data=(imgs_validation, msks_validation),\n",
    "                            verbose=1, shuffle=\"batch\",\n",
    "                            callbacks=model_callbacks)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Append training log\n",
    "    # with open(\"training.log\",\"a+\") as fp:\n",
    "    #     fp.write(\"{}: {}\\n\".format(datetime.datetime.now(),\n",
    "    #                              history.history[\"val_dice_coef\"]))\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Step 4: Evaluate the best model\n",
    "    \"\"\"\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Loading the best trained model ...\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    model = evaluate_model(model_filename, imgs_validation, msks_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some details on the processor of our system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\r\n",
      "CPU op-mode(s):        32-bit, 64-bit\r\n",
      "Byte Order:            Little Endian\r\n",
      "CPU(s):                8\r\n",
      "On-line CPU(s) list:   0-7\r\n",
      "Thread(s) per core:    2\r\n",
      "Core(s) per socket:    4\r\n",
      "Socket(s):             1\r\n",
      "NUMA node(s):          1\r\n",
      "Vendor ID:             GenuineIntel\r\n",
      "CPU family:            6\r\n",
      "Model:                 85\r\n",
      "Model name:            Intel(R) Xeon(R) Platinum 8124M CPU @ 3.00GHz\r\n",
      "Stepping:              4\r\n",
      "CPU MHz:               3388.850\r\n",
      "BogoMIPS:              6000.00\r\n",
      "Hypervisor vendor:     KVM\r\n",
      "Virtualization type:   full\r\n",
      "L1d cache:             32K\r\n",
      "L1i cache:             32K\r\n",
      "L2 cache:              1024K\r\n",
      "L3 cache:              25344K\r\n",
      "NUMA node0 CPU(s):     0-7\r\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves ida arat pku ospke\r\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras_preprocessing/image.py:836: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started script on 2019-01-24 01:35:47.132963\n",
      "args = Namespace(batch_size=128, blocktime=1, channels_first=False, data_filename='Task01_BrainTumour.h5', data_path='../data/144x144/', epochs=30, featuremaps=32, inference_filename='unet_model_for_decathlon.hdf5', keras_api=True, learningrate=0.0001, num_inter_threads=1, num_threads=8, output_path='./output/', print_model=True, use_augmentation=False, use_dropout=False, use_upsampling=True, weight_dice_loss=0.9)\n",
      "TensorFlow version: 1.12.0\n",
      "------------------------------\n",
      "Loading the data from HDF5 file ...\n",
      "------------------------------\n",
      "Batch size = 128\n",
      "Training image dimensions:   (58464, 144, 144, 4)\n",
      "Training mask dimensions:    (58464, 144, 144, 1)\n",
      "Validation image dimensions: (11232, 144, 144, 4)\n",
      "Validation mask dimensions:  (11232, 144, 144, 1)\n",
      "------------------------------\n",
      "Creating and compiling model ...\n",
      "------------------------------\n",
      "Using UpSampling2D\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "MRImages (InputLayer)           (None, 144, 144, 4)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encodeAa (Conv2D)               (None, 144, 144, 32) 1184        MRImages[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeAb (Conv2D)               (None, 144, 144, 32) 9248        encodeAa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolA (MaxPooling2D)            (None, 72, 72, 32)   0           encodeAb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeBa (Conv2D)               (None, 72, 72, 64)   18496       poolA[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeBb (Conv2D)               (None, 72, 72, 64)   36928       encodeBa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolB (MaxPooling2D)            (None, 36, 36, 64)   0           encodeBb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeCa (Conv2D)               (None, 36, 36, 128)  73856       poolB[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeCb (Conv2D)               (None, 36, 36, 128)  147584      encodeCa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolC (MaxPooling2D)            (None, 18, 18, 128)  0           encodeCb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeDa (Conv2D)               (None, 18, 18, 256)  295168      poolC[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeDb (Conv2D)               (None, 18, 18, 256)  590080      encodeDa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "poolD (MaxPooling2D)            (None, 9, 9, 256)    0           encodeDb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encodeEa (Conv2D)               (None, 9, 9, 512)    1180160     poolD[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "encodeEb (Conv2D)               (None, 9, 9, 512)    2359808     encodeEa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "upE (UpSampling2D)              (None, 18, 18, 512)  0           encodeEb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatD (Concatenate)           (None, 18, 18, 768)  0           upE[0][0]                        \n",
      "                                                                 encodeDb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decodeCa (Conv2D)               (None, 18, 18, 256)  1769728     concatD[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decodeCb (Conv2D)               (None, 18, 18, 256)  590080      decodeCa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "upC (UpSampling2D)              (None, 36, 36, 256)  0           decodeCb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatC (Concatenate)           (None, 36, 36, 384)  0           upC[0][0]                        \n",
      "                                                                 encodeCb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decodeBa (Conv2D)               (None, 36, 36, 128)  442496      concatC[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decodeBb (Conv2D)               (None, 36, 36, 128)  147584      decodeBa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "upB (UpSampling2D)              (None, 72, 72, 128)  0           decodeBb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatB (Concatenate)           (None, 72, 72, 192)  0           upB[0][0]                        \n",
      "                                                                 encodeBb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "decodeAa (Conv2D)               (None, 72, 72, 64)   110656      concatB[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "decodeAb (Conv2D)               (None, 72, 72, 64)   36928       decodeAa[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "upA (UpSampling2D)              (None, 144, 144, 64) 0           decodeAb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatA (Concatenate)           (None, 144, 144, 96) 0           upA[0][0]                        \n",
      "                                                                 encodeAb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "convOuta (Conv2D)               (None, 144, 144, 32) 27680       concatA[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "convOutb (Conv2D)               (None, 144, 144, 32) 9248        convOuta[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "PredictionMask (Conv2D)         (None, 144, 144, 1)  33          convOutb[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,846,945\n",
      "Trainable params: 7,846,945\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Writing model to './output/unet_model_for_decathlon.hdf5'\n",
      "------------------------------\n",
      "Fitting model with training data ...\n",
      "------------------------------\n",
      "Processing batch: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for training on batch: 42.46801447868347\n",
      "Processing batch: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2f9265f06134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                   \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                   \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                   onnx=True)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time elapsed for program = {} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bf538a615afd>\u001b[0m in \u001b[0;36mtrain_and_predict\u001b[0;34m(data_path, data_filename, batch_size, n_epoch, onnx)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             model.train_on_batch(imgs_train[i*batch_size:batch_size*(i+1)-1], \\\n\u001b[0;32m---> 39\u001b[0;31m                                  msks_train[i*batch_size:batch_size*(i+1)-1])\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Time for training on batch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"Started script on {}\".format(datetime.datetime.now()))\n",
    "\n",
    "print(\"args = {}\".format(args))\n",
    "os.system(\"uname -a\")\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "start_time = time.time()\n",
    "\n",
    "#TODO: Enable/Disable ONNX\n",
    "train_and_predict(args.data_path, \n",
    "                  args.data_filename,\n",
    "                  args.batch_size, \n",
    "                  args.epochs,\n",
    "                  onnx=True)\n",
    "\n",
    "print(\"Total time elapsed for program = {} seconds\".format(time.time() - start_time))\n",
    "print(\"Stopped script on {}\".format(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "   http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\n",
    "SPDX-License-Identifier: EPL-2.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
